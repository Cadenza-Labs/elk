{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba08e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from promptsource.templates import DatasetTemplates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0c3d5bd",
   "metadata": {},
   "source": [
    "# Load all datasets from HuggingFace `datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb150811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has to be loaded manually\n",
    "# load_dataset('story_cloze', data_dir='ASDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29eede6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset_names = [['ag_news'],['amazon_polarity'],['dbpedia_14'], ['imdb'], ['piqa']]\n",
    "super_glue_dataset_names = [['super_glue', 'boolq'],['super_glue', 'copa'], ['super_glue', 'rte']]\n",
    "glue_dataset_names =[['glue', 'qnli']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = {name[0]: load_dataset(*name) for name in normal_dataset_names}\n",
    "super_glue_dataset = {name[1]: load_dataset(*name) for name in super_glue_dataset_names}\n",
    "glue_dataset = {name[1]: load_dataset(*name) for name in glue_dataset_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c860607a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets = {**normal_dataset, **super_glue_dataset, **glue_dataset}\n",
    "\n",
    "len(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f676309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news dict_keys(['train', 'test'])\n",
      "amazon_polarity dict_keys(['train', 'test'])\n",
      "dbpedia_14 dict_keys(['train', 'test'])\n",
      "imdb dict_keys(['train', 'test', 'unsupervised'])\n",
      "piqa dict_keys(['train', 'test', 'validation'])\n",
      "boolq dict_keys(['train', 'validation', 'test'])\n",
      "copa dict_keys(['train', 'validation', 'test'])\n",
      "rte dict_keys(['train', 'validation', 'test'])\n",
      "qnli dict_keys(['train', 'validation', 'test'])\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, data_splits in all_datasets.items():\n",
    "    print(dataset_name, data_splits.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a42397e",
   "metadata": {},
   "source": [
    "# Load Promptsource `DatasetTemplates` for each Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162176ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ag_news': <promptsource.templates.DatasetTemplates at 0x16e047eb0>,\n",
       " 'amazon_polarity': <promptsource.templates.DatasetTemplates at 0x106b1d880>,\n",
       " 'dbpedia_14': <promptsource.templates.DatasetTemplates at 0x16e047df0>,\n",
       " 'imdb': <promptsource.templates.DatasetTemplates at 0x106b1dc70>,\n",
       " 'piqa': <promptsource.templates.DatasetTemplates at 0x16d6a3ac0>,\n",
       " 'boolq': <promptsource.templates.DatasetTemplates at 0x12e2e9820>,\n",
       " 'copa': <promptsource.templates.DatasetTemplates at 0x12e2d3fd0>,\n",
       " 'rte': <promptsource.templates.DatasetTemplates at 0x12e2d3f40>,\n",
       " 'qnli': <promptsource.templates.DatasetTemplates at 0x16e0552b0>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_dataset_to_dataset_template = {dataset_name: DatasetTemplates(dataset_name) for dataset_name in normal_dataset}\n",
    "super_glue_dataset_to_dataset_template = {dataset_name[1]: DatasetTemplates(f\"{dataset_name[0]}/{dataset_name[1]}\") for dataset_name in super_glue_dataset_names}\n",
    "glue_dataset_to_dataset_template = {dataset_name[1]: DatasetTemplates(f\"{dataset_name[0]}/{dataset_name[1]}\") for dataset_name in glue_dataset_names}\n",
    "\n",
    "dataset_to_dataset_template = {**normal_dataset_to_dataset_template, **super_glue_dataset_to_dataset_template, **glue_dataset_to_dataset_template}\n",
    "\n",
    "dataset_to_dataset_template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fc05ce7",
   "metadata": {},
   "source": [
    "# Load all prompt template names for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d931ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 prompts found for ag_news\n",
      "9 prompts found for amazon_polarity\n",
      "4 prompts found for dbpedia_14\n",
      "11 prompts found for imdb\n",
      "11 prompts found for piqa\n",
      "10 prompts found for boolq\n",
      "12 prompts found for copa\n",
      "10 prompts found for rte\n",
      "5 prompts found for qnli\n",
      "\n",
      "Found 79 total prompts for 9 datasets\n",
      "\n",
      "Total amount of prompts used in the paper: 96\n"
     ]
    }
   ],
   "source": [
    "normal_dataset_to_template_names = {dataset_name: DatasetTemplates(dataset_name).all_template_names for dataset_name in normal_dataset}\n",
    "super_glue_dataset_to_template_names = {dataset_name[1]: DatasetTemplates(f\"{dataset_name[0]}/{dataset_name[1]}\").all_template_names for dataset_name in super_glue_dataset_names}\n",
    "glue_dataset_to_template_names = {dataset_name[1]: DatasetTemplates(f\"{dataset_name[0]}/{dataset_name[1]}\").all_template_names for dataset_name in glue_dataset_names}\n",
    "\n",
    "dataset_to_template_names = {**normal_dataset_to_template_names, **super_glue_dataset_to_template_names, **glue_dataset_to_template_names}\n",
    "\n",
    "total_prompts = 0\n",
    "for dataset, prompt_name in dataset_to_template_names.items():\n",
    "    print(f\"{len(prompt_name)} prompts found for {dataset}\")\n",
    "    total_prompts +=len(prompt_name)\n",
    "\n",
    "print(f\"\\nFound {total_prompts} total prompts for {len(dataset_to_template_names)} datasets\")\n",
    "print(f\"\\nTotal amount of prompts used in the paper: {9 + 11 + 5 + 11 + 8 + 11 + 10+ 10 + 8 + 13 }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a67ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Names found for: ag_news\n",
      "['classify', 'classify_question_first', 'classify_with_choices', 'classify_with_choices_question_first', 'recommend', 'which_section', 'which_section_choices']\n",
      "\n",
      "Prompt Names found for: amazon_polarity\n",
      "['Is_this_product_review_positive', 'Is_this_review', 'Is_this_review_negative', 'User_recommend_this_product', 'convey_negative_or_positive_sentiment', 'flattering_or_not', 'negative_or_positive_tone', 'user_satisfied', 'would_you_buy']\n",
      "\n",
      "Prompt Names found for: dbpedia_14\n",
      "['given_a_choice_of_categories ', 'given_a_list_of_category_what_does_the_title_belong_to', 'given_list_what_category_does_the_paragraph_belong_to', 'pick_one_category_for_the_following_text']\n",
      "\n",
      "Prompt Names found for: imdb\n",
      "['Movie Expressed Sentiment', 'Movie Expressed Sentiment 2', 'Negation template for positive and negative', 'Reviewer Enjoyment', 'Reviewer Enjoyment Yes No', 'Reviewer Expressed Sentiment', 'Reviewer Opinion bad good choices', 'Reviewer Sentiment Feeling', 'Sentiment with choices ', 'Text Expressed Sentiment', 'Writer Expressed Sentiment']\n",
      "\n",
      "Prompt Names found for: piqa\n",
      "['Correct the solution', 'Correct the solution if false: from sol 1', 'Correct the solution if false: from sol 2', 'Does this solution make sense? sol1', 'Does this solution make sense? sol2', 'choose the most appropriate solution', 'finish_sentence_with_correct_choice', 'no prompt needed', 'pick_correct_choice_index', 'pick_correct_choice_with_choice_given_before_goal', 'what_is_the_correct_ending']\n",
      "\n",
      "Prompt Names found for: boolq\n",
      "['GPT-3 Style', 'I wonder…', 'after_reading', 'based on the following passage', 'based on the previous passage', 'could you tell me…', 'exam', 'exercise', 'valid_binary', 'yes_no_question']\n",
      "\n",
      "Prompt Names found for: copa\n",
      "['C1 or C2? premise, so/because…', 'best_option', 'cause_effect', 'choose', 'exercise', 'i_am_hesitating', 'more likely', 'plausible_alternatives', '…As a result, C1 or C2?', '…What could happen next, C1 or C2?', '…which may be caused by', '…why? C1 or C2']\n",
      "\n",
      "Prompt Names found for: rte\n",
      "['GPT-3 style', 'MNLI crowdsource', 'based on the previous passage', 'can we infer', 'does it follow that', 'does this imply', 'guaranteed true', 'justified in saying', 'must be true', 'should assume']\n",
      "\n",
      "Prompt Names found for: qnli\n",
      "['based only on', 'have all you need', 'imply', 'possible to answer', 'want to know']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset, prompt_names in dataset_to_template_names.items():\n",
    "    print('Prompt Names found for:', dataset)\n",
    "    print(f\"{prompt_names}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8adbcc62",
   "metadata": {},
   "source": [
    "# Let's test a prompt on an example from `ag_news` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1666e40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = all_datasets[\"ag_news\"][\"train\"][1]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53932c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classify',\n",
       " 'classify_question_first',\n",
       " 'classify_with_choices',\n",
       " 'classify_with_choices_question_first',\n",
       " 'recommend',\n",
       " 'which_section',\n",
       " 'which_section_choices']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_template_names['ag_news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0b580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market. \\nWhat label best describes this news article?', 'Business']\n"
     ]
    }
   ],
   "source": [
    "ag_news_template = dataset_to_dataset_template['ag_news']\n",
    "\n",
    "for prompt_idx in dataset_to_template_names['ag_news']:\n",
    "    prompt = ag_news_template[prompt_idx]\n",
    "    print(prompt.apply(example))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d891dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "84b549b0a981078fe8ab630e85412ecf07c98354be1546c2563d7f951d3a915d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
