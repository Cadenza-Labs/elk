from elk.files import args_to_uuid, elk_cache_dir
from .extraction.extraction_main import get_hiddens_path, run as run_extraction
from .extraction.parser import (
    add_saveable_args,
    add_unsaveable_args,
    get_extraction_parser,
)
from .training.parser import add_train_args, get_training_parser
from .training.train import train
from argparse import ArgumentParser
from pathlib import Path
from transformers import AutoConfig, PretrainedConfig
import json


def run():
    parser = ArgumentParser(add_help=False)
    subparsers = parser.add_subparsers(dest="command", required=True)

    subparsers.add_parser(
        "extract",
        help="Extract hidden states from a model.",
        parents=[get_extraction_parser()],
    )
    subparsers.add_parser(
        "train",
        help=(
            "Train a set of ELK probes on hidden states from `elk extract`. "
            "The first argument has to be the name you gave to the extraction."
        ),
        parents=[get_training_parser()],
    )
    subparsers.add_parser(
        "elicit",
        help=(
            "Extract and train a set of ELK probes "
            "on hidden states from `elk extract`. "
        ),
        parents=[get_extraction_parser(), get_training_parser(name=False)],
        conflict_handler="resolve",
    )

    subparsers.add_parser(
        "eval", help="Evaluate a set of ELK probes generated by `elk train`."
    )
    args = parser.parse_args()

    normalize_args_inplace(args)

    for key in list(vars(args).keys()):
        print("{}: {}".format(key, vars(args)[key]))

    # TODO: Implement the rest of the CLI
    if args.command == "extract":
        run_extraction(args)
    elif args.command == "train":
        train(args)
    elif args.command == "elicit":
        # Extract the hidden states if they're not already there
        args.name = args_to_uuid(args)
        cache_dir = elk_cache_dir() / args.name
        missing_layers = find_missing_layers(args)
        if missing_layers:
            if cache_dir.exists():
                print(
                    f"Found cache dir \033[1m{cache_dir}\033[0m"
                    f" but it's missing layers {', '.join(missing_layers)}"
                )

            old_layers = args.layers
            args.layers = missing_layers
            run_extraction(args)
            args.layers = old_layers
        else:
            print(
                f"Cache dir \033[1m{cache_dir}\033[0m exists, "
                "skip extraction of hidden states"
            )  # bold

        # Train the probes
        train(args)
    elif args.command == "eval":
        raise NotImplementedError
    else:
        raise ValueError(f"Unknown command {args.command}")


def normalize_args_inplace(args):
    # Default to CUDA iff available
    if args.device is None:
        import torch

        args.device = "cuda" if torch.cuda.is_available() else "cpu"

    if model := getattr(args, "model", None):
        config_path = Path(__file__).parent / "default_config.json"
        with open(config_path, "r") as f:
            default_config = json.load(f)
            model_shortcuts = default_config["model_shortcuts"]

        # Dereference shortcut
        args.model = model_shortcuts.get(model, model)
        config = AutoConfig.from_pretrained(args.model)
        assert isinstance(config, PretrainedConfig)

        num_layers = getattr(config, "num_layers", config.num_hidden_layers)
        assert isinstance(num_layers, int)

        if args.layers and args.layer_stride > 1:
            raise ValueError(
                "Cannot use both --layers and --layer-stride. Please use only one."
            )
        elif args.layer_stride > 1:
            # the last layer is often the most interesting
            # layers = [..., num_layers - 1 - layer_stride, num_layers - 1]
            args.layers = list(range(num_layers - 1, -1, -args.layer_stride)).reverse()


def find_missing_layers(args):
    missing_layers = []
    for layer in args.layers:
        cache_dir = elk_cache_dir() / args.name
        train_layer_path = get_hiddens_path(cache_dir, "train", layer)
        validation_layer_path = get_hiddens_path(cache_dir, "validation", layer)
        if not train_layer_path.exists() or not validation_layer_path.exists():
            missing_layers.append(layer)
    return missing_layers


if __name__ == "__main__":
    run()
